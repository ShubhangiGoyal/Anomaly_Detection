{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset : MNIST Number Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'  # suppress CPU msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(raw_data_x, raw_data_y, idx):\n",
    "  label = raw_data_y[idx]  # like '5'\n",
    "  print(\"digit = \", str(label), \"\\n\")\n",
    "  pixels = np.array(raw_data_x[idx])  # target row of pixels\n",
    "  pixels = pixels.reshape((28,28))\n",
    "  plt.rcParams['toolbar'] = 'None' \n",
    "  plt.imshow(pixels, cmap=plt.get_cmap('gray_r'))\n",
    "  plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogger(K.callbacks.Callback):\n",
    "  def __init__(self, n):\n",
    "    self.n = n   # print loss every n epochs\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if epoch % self.n == 0:\n",
    "      curr_loss =logs.get('loss')\n",
    "      print(\"epoch = %4d loss = %0.6f\" % (epoch, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin MNIST anomaly detect using an autoencoder \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  # 0. get started\n",
    "  print(\"Begin MNIST anomaly detect using an autoencoder \")\n",
    "  np.random.seed(1)  # not used\n",
    "\n",
    "  # 1. load data into memory\n",
    "  # 2. define autoencoder model\n",
    "  # 3. compile model\n",
    "  # 4. train model\n",
    "  # 5. save model\n",
    "  # 6. use model to find anomaly\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Dataset (1000 images from MNIST dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Keras version MNIST data into memory \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. load data\n",
    "print(\"Loading Keras version MNIST data into memory \\n\")\n",
    "data_file = \"mnist_keras_1000.txt\"\n",
    "data_x = np.loadtxt(data_file, delimiter=\" \",\n",
    "  usecols=range(2,786), dtype=np.float32)\n",
    "labels = np.loadtxt(data_file, delimiter=\" \",\n",
    "  usecols=[0], dtype=np.float32)\n",
    "norm_x = data_x / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Autoencoder model (784-100-50-100-784 with tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a 784-100-50-100-784 autoencoder \n"
     ]
    }
   ],
   "source": [
    "# 2. define autoencoder model\n",
    "print(\"Creating a 784-100-50-100-784 autoencoder \")\n",
    "my_init = K.initializers.glorot_uniform(seed=1)\n",
    "autoenc = K.models.Sequential()\n",
    "autoenc.add(K.layers.Dense(input_dim=784, units=100, \n",
    "  activation='tanh', kernel_initializer=my_init))\n",
    "autoenc.add(K.layers.Dense(units=50, \n",
    "  activation='tanh', kernel_initializer=my_init))\n",
    "autoenc.add(K.layers.Dense(units=100, \n",
    "  activation='tanh', kernel_initializer=my_init)) \n",
    "autoenc.add(K.layers.Dense(units=784,\n",
    "  activation='tanh', kernel_initializer=my_init)) \n",
    "\n",
    "# 3. compile model\n",
    "simple_adam = K.optimizers.adam()  \n",
    "autoenc.compile(loss='mean_squared_error',\n",
    "  optimizer=simple_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model with 400 epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "epoch =    0 loss = 0.076969\n",
      "epoch =  100 loss = 0.012946\n",
      "epoch =  200 loss = 0.011671\n",
      "epoch =  300 loss = 0.010599\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# 4. train model\n",
    "print(\"Starting training\")\n",
    "max_epochs = 400\n",
    "my_logger = MyLogger(n=100)\n",
    "h = autoenc.fit(norm_x, norm_x, batch_size=40, \n",
    "  epochs=max_epochs, verbose=0, callbacks=[my_logger])\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Anomaly :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. find most anomalous data item\n",
    "N = len(norm_x)\n",
    "max_se = 0.0; max_ix = 0\n",
    "predicteds = autoenc.predict(norm_x)\n",
    "for i in range(N):\n",
    "  diff = norm_x[i] - predicteds[i]\n",
    "  curr_se = np.sum(diff * diff)\n",
    "  if curr_se > max_se:\n",
    "    max_se = curr_se; max_ix = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most anomalous digit is at index  149\n",
      "digit =  2 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data_x = data_x.astype(np.int)\n",
    "raw_data_y = labels.astype(np.int)\n",
    "print(\"Most anomalous digit is at index \", max_ix)\n",
    "display(raw_data_x, raw_data_y, max_ix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
